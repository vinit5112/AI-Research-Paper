# AI Research Papers and Topics

This repository provides a curated list of influential research papers and topics in the field of artificial intelligence, particularly focusing on transformer architectures, pre-training, scaling laws, generative AI, model evaluation metrics, parameter-efficient fine-tuning, and advanced prompting techniques.

## Transformer Architecture

- **Attention is All You Need**: The seminal paper introducing the Transformer model.
- **BLOOM: BigScience 176B Model**: An overview of the BLOOM model with 176 billion parameters.
- **Vector Space Models**: Techniques and theories related to vector space models in NLP.

## Pre-training and Scaling Laws

- **Scaling Laws for Neural Language Models**: Insights into how model performance scales with size and compute.
- **What Language Model Architecture and Pretraining Objective Work Best for Zero-Shot Generalization?**: Exploring effective architectures and pretraining for zero-shot tasks.
- **LLaMA: Open and Efficient Foundation Language Models**: Meta AI's proposal for efficient large language models.

## Scaling Laws and Compute-Optimal Models

- **Language Models are Few-Shot Learners**: Discussion on few-shot learning capabilities of large language models.
- **Training Compute-Optimal Large Language Models**: Strategies for training models efficiently with compute resources.
- **BloombergGPT: A Large Language Model for Finance**: The application of LLMs in financial contexts.

## Generative AI Lifecycle

- **Generative AI on AWS: Building Context-Aware, Multimodal Reasoning Applications**: A guide to building generative AI applications using AWS.

## Multi-task and Instruction Fine-Tuning

- **Scaling Instruction-Finetuned Language Models**: Techniques for scaling instruction-based fine-tuning.
- **Introducing FLAN: More Generalizable Language Models with Instruction Fine-Tuning**: An overview of the FLAN models and their generalization capabilities.

## Model Evaluation Metrics

- **HELM - Holistic Evaluation of Language Models**: Framework for evaluating language models holistically.
- **General Language Understanding Evaluation (GLUE) Benchmark**: Standard benchmarks for evaluating language understanding.
- **SuperGLUE**: An advanced benchmark extending GLUE.
- **ROUGE: A Package for Automatic Evaluation of Summaries**: Metrics for evaluating summary generation.
- **Measuring Massive Multitask Language Understanding (MMLU)**: Evaluation of models on a variety of tasks.
- **BigBench-Hard - Beyond the Imitation Game**: Metrics for extrapolating model capabilities.

## Parameter-Efficient Fine-Tuning (PEFT)

- **Scaling Down to Scale Up: A Guide to Parameter-Efficient Fine-Tuning**: Approaches to efficient fine-tuning.
- **On the Effectiveness of Parameter-Efficient Fine-Tuning**: Evaluating the effectiveness of various fine-tuning techniques.

## LoRA

- **LoRA Low-Rank Adaptation of Large Language Models**: Techniques for adapting large models using low-rank methods.
- **QLoRA: Efficient Finetuning of Quantized LLMs**: Efficient fine-tuning methods for quantized models.

## Prompt Tuning with Soft Prompts

- **The Power of Scale for Parameter-Efficient Prompt Tuning**: Effective prompt tuning techniques for large models.

## Reinforcement Learning from Human Feedback (RLHF)

- **Training Language Models to Follow Instructions with Human Feedback**: Methods for training models using human feedback.
- **Learning to Summarize from Human Feedback**: Approaches for summarization using RLHF.

## Proximal Policy Optimization (PPO)

- **Proximal Policy Optimization Algorithms**: Details on PPO algorithms.
- **Direct Preference Optimization: Your Language Model is Secretly a Reward Model**: Exploring preference optimization in language models.

## Scaling Human Feedback

- **Constitutional AI: Harmlessness from AI Feedback**: Ensuring AI systems are harmless using feedback mechanisms.

## Advanced Prompting Techniques

- **Chain-of-Thought Prompting Elicits Reasoning in Large Language Models**: Techniques for eliciting reasoning through prompting.
- **PAL: Program-Aided Language Models**: Integration of programmatic aids in language models.
- **ReAct: Synergizing Reasoning and Acting in Language Models**: Approaches to combining reasoning and acting capabilities in models.
